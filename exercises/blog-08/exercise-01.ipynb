{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ade98402",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/shang-vikas/series1-coding-exercises/blob/main/exercises/blog-08/exercise-01.ipynb)\n",
    "\n",
    "# ðŸ§ª Exercise 2 â€” Build Self-Attention From Scratch\n",
    "\n",
    "## Goal\n",
    "\n",
    "Make attention feel mechanical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "584c4a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.10.0-2-cp310-none-macosx_11_0_arm64.whl.metadata (31 kB)\n",
      "Collecting filelock (from torch)\n",
      "  Downloading filelock-3.24.3-py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Users/shang/Library/Python/3.10/lib/python/site-packages (from torch) (4.15.0)\n",
      "Collecting sympy>=1.13.3 (from torch)\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx>=2.5.1 (from torch)\n",
      "  Using cached networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting jinja2 (from torch)\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting fsspec>=0.8.5 (from torch)\n",
      "  Downloading fsspec-2026.2.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch)\n",
      "  Using cached markupsafe-3.0.3-cp310-cp310-macosx_11_0_arm64.whl.metadata (2.7 kB)\n",
      "Downloading torch-2.10.0-2-cp310-none-macosx_11_0_arm64.whl (79.4 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m79.4/79.4 MB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2026.2.0-py3-none-any.whl (202 kB)\n",
      "Using cached networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Downloading filelock-3.24.3-py3-none-any.whl (24 kB)\n",
      "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Using cached markupsafe-3.0.3-cp310-cp310-macosx_11_0_arm64.whl (12 kB)\n",
      "Installing collected packages: mpmath, sympy, networkx, MarkupSafe, fsspec, filelock, jinja2, torch\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m8/8\u001b[0m [torch]32m7/8\u001b[0m [torch]]x]\n",
      "\u001b[1A\u001b[2KSuccessfully installed MarkupSafe-3.0.3 filelock-3.24.3 fsspec-2026.2.0 jinja2-3.1.6 mpmath-1.3.0 networkx-3.4.2 sympy-1.14.0 torch-2.10.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/opt/homebrew/opt/python@3.10/bin/python3.10 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14f2db49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention matrix:\n",
      "tensor([[1.0000e+00, 7.6036e-12, 1.7051e-06, 8.4510e-11],\n",
      "        [5.2877e-03, 9.9469e-01, 3.3425e-06, 1.7669e-05],\n",
      "        [4.2503e-12, 1.9294e-13, 1.0000e+00, 9.4086e-08],\n",
      "        [1.7502e-07, 1.0000e+00, 7.7696e-12, 1.8689e-06]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "batch = 1\n",
    "seq = 4\n",
    "dim = 8\n",
    "\n",
    "x = torch.randn(batch, seq, dim)\n",
    "\n",
    "Wq = torch.randn(dim, dim)\n",
    "Wk = torch.randn(dim, dim)\n",
    "Wv = torch.randn(dim, dim)\n",
    "\n",
    "Q = x @ Wq\n",
    "K = x @ Wk\n",
    "V = x @ Wv\n",
    "\n",
    "scores = Q @ K.transpose(-2, -1) / dim**0.5\n",
    "weights = F.softmax(scores, dim=-1)\n",
    "\n",
    "output = weights @ V\n",
    "\n",
    "print(\"Attention matrix:\")\n",
    "print(weights[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0020b03",
   "metadata": {},
   "source": [
    "Each row is a routing decision.\n",
    "\n",
    "Each token decides how much every other token matters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00961a05",
   "metadata": {},
   "source": [
    "## Modify One Token\n",
    "\n",
    "Change token 0 slightly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ebd307f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original attention matrix:\n",
      "tensor([[1.0000e+00, 7.6036e-12, 1.7051e-06, 8.4510e-11],\n",
      "        [5.2877e-03, 9.9469e-01, 3.3425e-06, 1.7669e-05],\n",
      "        [4.2503e-12, 1.9294e-13, 1.0000e+00, 9.4086e-08],\n",
      "        [1.7502e-07, 1.0000e+00, 7.7696e-12, 1.8689e-06]])\n",
      "\n",
      "Modified attention matrix:\n",
      "tensor([[1.0000e+00, 8.3065e-25, 4.7873e-17, 1.0239e-24],\n",
      "        [3.5539e-05, 9.9994e-01, 3.3602e-06, 1.7763e-05],\n",
      "        [1.4553e-13, 1.9294e-13, 1.0000e+00, 9.4086e-08],\n",
      "        [1.3774e-12, 1.0000e+00, 7.7696e-12, 1.8689e-06]])\n",
      "\n",
      "Difference:\n",
      "tensor([[-1.6689e-06,  7.6036e-12,  1.7051e-06,  8.4510e-11],\n",
      "        [ 5.2521e-03, -5.2521e-03, -1.7649e-08, -9.3296e-08],\n",
      "        [ 4.1048e-12,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.7501e-07, -1.1921e-07, -8.6736e-19, -2.2737e-13]])\n"
     ]
    }
   ],
   "source": [
    "# Modify token 0\n",
    "x_modified = x.clone()\n",
    "x_modified[0, 0] += 0.5  # Small change to first token\n",
    "\n",
    "Q_modified = x_modified @ Wq\n",
    "K_modified = x_modified @ Wk\n",
    "V_modified = x_modified @ Wv\n",
    "\n",
    "scores_modified = Q_modified @ K_modified.transpose(-2, -1) / dim**0.5\n",
    "weights_modified = F.softmax(scores_modified, dim=-1)\n",
    "\n",
    "print(\"Original attention matrix:\")\n",
    "print(weights[0])\n",
    "print(\"\\nModified attention matrix:\")\n",
    "print(weights_modified[0])\n",
    "print(\"\\nDifference:\")\n",
    "print((weights - weights_modified)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179d07e4",
   "metadata": {},
   "source": [
    "**Observe attention matrix changes everywhere.**\n",
    "\n",
    "This demonstrates contextualization."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
