{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a63bfd1",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/shang-vikas/series1-coding-exercises/blob/main/exercises/blog-08/exercise-00.ipynb)\n",
    "\n",
    "# ðŸ§ª Exercise 1 â€” Embeddings + Positional Encoding (Make Order Visible)\n",
    "\n",
    "## Goal\n",
    "\n",
    "Show that:\n",
    "\n",
    "Without positional encoding, order disappears.\n",
    "\n",
    "With positional encoding, order becomes numerically present."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b303ca40",
   "metadata": {},
   "source": [
    "## Step 1 â€” Fake Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4688616c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "vocab_size = 100\n",
    "embed_dim = 16\n",
    "seq_len = 5\n",
    "\n",
    "embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "\n",
    "tokens = torch.tensor([[5, 8, 3, 2, 9]])  # shape (1, 5)\n",
    "x = embedding(tokens)\n",
    "\n",
    "print(\"Embeddings shape:\", x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9fdf31e",
   "metadata": {},
   "source": [
    "Now reorder tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5f5df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_shuffled = torch.tensor([[3, 5, 9, 8, 2]])\n",
    "x_shuffled = embedding(tokens_shuffled)\n",
    "\n",
    "print(\"Difference norm:\", (x - x_shuffled).norm())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6e4fc0",
   "metadata": {},
   "source": [
    "**Observation:**\n",
    "\n",
    "The model sees a different set of vectors but doesn't know their position."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fb102d",
   "metadata": {},
   "source": [
    "## Step 2 â€” Add Positional Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92eac8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "position = torch.arange(seq_len).unsqueeze(0)\n",
    "pos_embedding = nn.Embedding(seq_len, embed_dim)\n",
    "\n",
    "x_with_pos = x + pos_embedding(position)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec767c19",
   "metadata": {},
   "source": [
    "Now order is baked into vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9f2041",
   "metadata": {},
   "source": [
    "## ðŸ’¡ Teaching Point\n",
    "\n",
    "Order is not remembered.\n",
    "\n",
    "Order is injected numerically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605f5d1b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e09fee",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a943dcac",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383800fa",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce637f25",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
