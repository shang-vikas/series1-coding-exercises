{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Exercise 02: Train a 2-Layer Network on Real Data (Manual Backprop)\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/shang-vikas/series1-coding-exercises/blob/main/exercises/blog-031/exercise-02.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ numpy is already installed\n",
            "âœ“ scikit-learn is already installed\n"
          ]
        }
      ],
      "source": [
        "# Install required packages using the kernel's Python interpreter\n",
        "import sys\n",
        "import subprocess\n",
        "import importlib\n",
        "\n",
        "def install_if_missing(package, import_name=None):\n",
        "    \"\"\"Install package if it's not already installed.\"\"\"\n",
        "    if import_name is None:\n",
        "        import_name = package\n",
        "\n",
        "    try:\n",
        "        importlib.import_module(import_name)\n",
        "        print(f\"âœ“ {package} is already installed\")\n",
        "    except ImportError:\n",
        "        print(f\"Installing {package}....\")\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
        "        print(f\"âœ“ {package} installed successfully\")\n",
        "\n",
        "# Install required packages\n",
        "install_if_missing(\"numpy\")\n",
        "install_if_missing(\"scikit-learn\", \"sklearn\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This is your \"you now understand training\" checkpoint."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 1 â€” Load Real Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "# Load real dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target.reshape(-1, 1)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Normalize features (important!)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This dataset predicts:\n",
        "\n",
        "- 0 = malignant\n",
        "- 1 = benign\n",
        "\n",
        "**30 real medical features.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 2 â€” Initialize Network\n",
        "\n",
        "We'll use:\n",
        "\n",
        "**Input (30) â†’ Hidden (16) â†’ Output (1)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "input_dim = X_train.shape[1]\n",
        "hidden_dim = 16\n",
        "\n",
        "W1 = np.random.randn(input_dim, hidden_dim) * 0.01\n",
        "b1 = np.zeros((1, hidden_dim))\n",
        "\n",
        "W2 = np.random.randn(hidden_dim, 1) * 0.01\n",
        "b2 = np.zeros((1, 1))\n",
        "\n",
        "lr = 0.05 # learning rate - how much we update the weights by each iteration."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 3 â€” Define Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "def relu(z):\n",
        "    return np.maximum(0, z)\n",
        "\n",
        "def relu_derivative(z):\n",
        "    return (z > 0).astype(float)\n",
        "\n",
        "def sigmoid(z):\n",
        "    return 1 / (1 + np.exp(-z))\n",
        "\n",
        "def compute_loss(p, y):\n",
        "    eps = 1e-8\n",
        "    return -np.mean(y * np.log(p + eps) + (1 - y) * np.log(1 - p + eps))\n",
        "\n",
        "def accuracy(p, y):\n",
        "    preds = (p > 0.5).astype(int)\n",
        "    return np.mean(preds == y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 4 â€” Training Loop (Full Batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0 | Loss: 0.6932 | Train Acc: 0.3714\n",
            "Epoch 50 | Loss: 0.6510 | Train Acc: 0.6330\n",
            "Epoch 100 | Loss: 0.4344 | Train Acc: 0.9341\n",
            "Epoch 150 | Loss: 0.2253 | Train Acc: 0.9560\n",
            "Epoch 200 | Loss: 0.1445 | Train Acc: 0.9714\n",
            "Epoch 250 | Loss: 0.1116 | Train Acc: 0.9736\n",
            "Epoch 300 | Loss: 0.0935 | Train Acc: 0.9824\n",
            "Epoch 350 | Loss: 0.0833 | Train Acc: 0.9824\n",
            "Epoch 400 | Loss: 0.0767 | Train Acc: 0.9824\n",
            "Epoch 450 | Loss: 0.0721 | Train Acc: 0.9824\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(500):\n",
        "\n",
        "    # Forward\n",
        "    z1 = X_train @ W1 + b1\n",
        "    a1 = relu(z1)\n",
        "\n",
        "    z2 = a1 @ W2 + b2\n",
        "    p = sigmoid(z2)\n",
        "\n",
        "    loss = compute_loss(p, y_train)\n",
        "\n",
        "    # Backward\n",
        "    dz2 = p - y_train\n",
        "    dW2 = a1.T @ dz2 / len(X_train)\n",
        "    db2 = np.mean(dz2, axis=0, keepdims=True)\n",
        "\n",
        "    da1 = dz2 @ W2.T\n",
        "    dz1 = da1 * relu_derivative(z1)\n",
        "\n",
        "    dW1 = X_train.T @ dz1 / len(X_train)\n",
        "    db1 = np.mean(dz1, axis=0, keepdims=True)\n",
        "\n",
        "    # Update\n",
        "    W2 -= lr * dW2\n",
        "    b2 -= lr * db2\n",
        "    W1 -= lr * dW1\n",
        "    b1 -= lr * db1\n",
        "\n",
        "    if epoch % 50 == 0:\n",
        "        train_acc = accuracy(p, y_train)\n",
        "        print(f\"Epoch {epoch} | Loss: {loss:.4f} | Train Acc: {train_acc:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 5 â€” Evaluate on Test Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.9912280701754386\n"
          ]
        }
      ],
      "source": [
        "z1 = X_test @ W1 + b1\n",
        "a1 = relu(z1)\n",
        "z2 = a1 @ W2 + b2\n",
        "p_test = sigmoid(z2)\n",
        "\n",
        "test_acc = accuracy(p_test, y_test)\n",
        "print(\"Test Accuracy:\", test_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You should reach **~95%+ accuracy**.\n",
        "\n",
        "With no frameworks.\n",
        "\n",
        "No autograd.\n",
        "\n",
        "Just the core engine."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This is data with:\n",
        "\n",
        "- Real noisy data\n",
        "- Real feature correlations\n",
        "- Real class imbalance\n",
        "- Real generalization gap\n",
        "\n",
        "**Now you can:**\n",
        "\n",
        "- Change hidden size â†’ watch overfitting\n",
        "- Increase learning rate â†’ watch divergence\n",
        "- Remove normalization â†’ watch training destabilize\n",
        "- Add L2 regularization â†’ see generalization improve\n",
        "\n",
        "Now the system behaves like real ML."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ’¡ Reflection Prompts\n",
        "\n",
        "- What happens if `hidden_dim = 128`?\n",
        "- What if you remove ReLU?\n",
        "- What if you increase `lr` to `0.5`?\n",
        "- What if you train for 5000 epochs?\n",
        "- What happens if you initialize weights too large?\n",
        "\n",
        "**You'll see:**\n",
        "\n",
        "- Vanishing/exploding behavior\n",
        "- Overfitting\n",
        "- Optimization instability\n",
        "\n",
        "On real data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Why This Is Powerful\n",
        "\n",
        "You just trained a real medical classifier using:\n",
        "\n",
        "- manual gradient computation\n",
        "- no frameworks\n",
        "- no magic\n",
        "\n",
        "**If you understand this exercise deeply,**\n",
        "\n",
        "**you understand 90% of deep learning training.**\n",
        "\n",
        "The rest is engineering scale."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
