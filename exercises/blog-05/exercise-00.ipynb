{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1584ea5",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/shang-vikas/series1-coding-exercises/blob/main/exercises/blog-05/exercise-00.ipynb)\n",
    "\n",
    "# ðŸ§ª Exercise 1 â€” Why Bag of Words Fails\n",
    "\n",
    "\n",
    "**Goal:** Destroy order mechanically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb60ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "sentences = [\"dog bites man\", \"man bites dog\"]\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(sentences)\n",
    "\n",
    "print(\"Vocabulary:\", vectorizer.vocabulary_)\n",
    "print(\"Vectors:\\n\", X.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d07ff52",
   "metadata": {},
   "source": [
    "**Expected output:**\n",
    "\n",
    "```\n",
    "Vocabulary: {'dog': 0, 'bites': 1, 'man': 2}\n",
    "Vectors:\n",
    "[[1 1 1]\n",
    " [1 1 1]]\n",
    "```\n",
    "\n",
    "Same vector.\n",
    "\n",
    "Different meaning.\n",
    "\n",
    "This is the mechanical reason RNNs existed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7eaf701",
   "metadata": {},
   "source": [
    "# ðŸ§ª Exercise 2 â€” Manual Tiny RNN Forward Pass\n",
    "\n",
    "**Goal:** See recurrence happen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019bf90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Input size = 3, hidden size = 2\n",
    "Wx = np.random.randn(3, 2)\n",
    "Wh = np.random.randn(2, 2)\n",
    "b = np.zeros((1, 2))\n",
    "\n",
    "def rnn_step(x, h_prev):\n",
    "    return np.tanh(x @ Wx + h_prev @ Wh + b)\n",
    "\n",
    "# Sequence of 3 one-hot inputs\n",
    "x_seq = [\n",
    "    np.array([[1,0,0]]),\n",
    "    np.array([[0,1,0]]),\n",
    "    np.array([[0,0,1]])\n",
    "]\n",
    "\n",
    "h = np.zeros((1,2))\n",
    "\n",
    "for t, x in enumerate(x_seq):\n",
    "    h = rnn_step(x, h)\n",
    "    print(f\"Step {t+1} hidden:\", h)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7635f48",
   "metadata": {},
   "source": [
    "**Observe:**\n",
    "\n",
    "- Same Wx, Wh reused\n",
    "- Hidden state evolves\n",
    "- State depends on previous state\n",
    "\n",
    "This is recurrence in its purest form."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b36a4f6",
   "metadata": {},
   "source": [
    "# ðŸ§ª Exercise 3 â€” Show Hidden State Overwrite\n",
    "\n",
    "Now prepend noise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3498543b",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = [np.random.randn(1,3) for _ in range(5)]\n",
    "new_seq = noise + x_seq\n",
    "\n",
    "h = np.zeros((1,2))\n",
    "\n",
    "for t, x in enumerate(new_seq):\n",
    "    h = rnn_step(x, h)\n",
    "\n",
    "print(\"Final hidden state after noise:\", h)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2860bd",
   "metadata": {},
   "source": [
    "Now compare:\n",
    "\n",
    "- Without noise\n",
    "- With noise\n",
    "\n",
    "Early signal gets overwritten.\n",
    "\n",
    "Memory fragility becomes obvious."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb04959d",
   "metadata": {},
   "source": [
    "# ðŸ§ª Exercise 4 â€” Train a Real RNN (Tiny Shakespeare)\n",
    "\n",
    "We'll do character-level modeling.\n",
    "\n",
    "## Step 1 â€” Load tiny dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afa9157",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import requests\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\"\n",
    "text = requests.get(url).text[:50000]  # small subset\n",
    "\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "\n",
    "char_to_idx = {ch:i for i,ch in enumerate(chars)}\n",
    "idx_to_char = {i:ch for ch,i in char_to_idx.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6eeef0b",
   "metadata": {},
   "source": [
    "## Step 2 â€” Create sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a131586a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 50\n",
    "\n",
    "data = []\n",
    "for i in range(len(text) - sequence_length):\n",
    "    seq = text[i:i+sequence_length]\n",
    "    target = text[i+1:i+sequence_length+1]\n",
    "    data.append((seq, target))\n",
    "\n",
    "def encode(seq):\n",
    "    return torch.tensor([char_to_idx[c] for c in seq])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04061917",
   "metadata": {},
   "source": [
    "## Step 3 â€” Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5de2ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleRNN(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, vocab_size)\n",
    "        self.rnn = nn.RNN(vocab_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        out, _ = self.rnn(x)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "model = SimpleRNN(vocab_size, hidden_size=128)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.003)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390d1208",
   "metadata": {},
   "source": [
    "## Step 4 â€” Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca42e8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for i in range(0, 1000):  # small subset for speed\n",
    "        seq, target = data[i]\n",
    "        x = encode(seq).unsqueeze(0)\n",
    "        y = encode(target)\n",
    "\n",
    "        out = model(x)\n",
    "        loss = criterion(out.view(-1, vocab_size), y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / 1000\n",
    "\n",
    "for epoch in range(5):\n",
    "    loss = train_epoch()\n",
    "    print(f\"Epoch {epoch+1} | Loss: {loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d12b66",
   "metadata": {},
   "source": [
    "Now they see:\n",
    "\n",
    "- Same weights reused per step\n",
    "- Sequential processing\n",
    "- Loss decreasing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dcfa7f9",
   "metadata": {},
   "source": [
    "# ðŸ§ª Exercise 5 â€” Demonstrate Vanishing Gradient\n",
    "\n",
    "Increase sequence length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5742637",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 200  # try 20, 50, 200\n",
    "\n",
    "# Recreate data with new sequence length\n",
    "data = []\n",
    "for i in range(len(text) - sequence_length):\n",
    "    seq = text[i:i+sequence_length]\n",
    "    target = text[i+1:i+sequence_length+1]\n",
    "    data.append((seq, target))\n",
    "\n",
    "# Reinitialize model\n",
    "model = SimpleRNN(vocab_size, hidden_size=128)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.003)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df1cc28",
   "metadata": {},
   "source": [
    "Then inspect gradients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72cda8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run one training step to get gradients\n",
    "seq, target = data[0]\n",
    "x = encode(seq).unsqueeze(0)\n",
    "y = encode(target)\n",
    "\n",
    "out = model(x)\n",
    "loss = criterion(out.view(-1, vocab_size), y)\n",
    "\n",
    "optimizer.zero_grad()\n",
    "loss.backward()\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    if param.grad is not None:\n",
    "        print(name, param.grad.norm().item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aedd7a1f",
   "metadata": {},
   "source": [
    "As sequence length increases:\n",
    "\n",
    "- Early layers' gradients shrink\n",
    "- Training slows\n",
    "\n",
    "This makes vanishing gradient concrete."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f361f3",
   "metadata": {},
   "source": [
    "# ðŸ§ª Exercise 6 â€” Serial Bottleneck Demonstration\n",
    "\n",
    "Measure time per epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157da83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "train_epoch()\n",
    "end = time.time()\n",
    "\n",
    "print(\"Time per epoch:\", end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6180e4ff",
   "metadata": {},
   "source": [
    "Now test:\n",
    "\n",
    "- `sequence_length = 20`\n",
    "- `sequence_length = 200`\n",
    "\n",
    "Longer sequence â†’ slower epoch.\n",
    "\n",
    "Why?\n",
    "\n",
    "Because RNN must compute:\n",
    "\n",
    "t1 â†’ t2 â†’ t3 â†’ ... â†’ t200\n",
    "\n",
    "No parallel shortcut.\n",
    "\n",
    "This is the structural bottleneck."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d829cf",
   "metadata": {},
   "source": [
    "## What They Just Saw\n",
    "\n",
    "- Bag of words destroys order.\n",
    "- RNN carries evolving hidden state.\n",
    "- Memory gets overwritten.\n",
    "- Gradients weaken over long sequences.\n",
    "- Computation is serial.\n",
    "- Training time scales with sequence length.\n",
    "\n",
    "No mythology.\n",
    "\n",
    "No metaphors.\n",
    "\n",
    "Just mechanics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198e75c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb51c718",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a334b40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964ae826",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446f7e86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3e193b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0307d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ccc8742",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d041da50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c567b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245198c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfacbf44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d6c1fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9f6131",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c71f4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d314aa2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b68dc36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b849500",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c809e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e62f7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932d2af2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1b481a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f29285",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c68398",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b64ee11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb28a1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563f2604",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006963dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0352f1f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b6b412",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3b5abb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508e31a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9888c44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e896a942",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
