{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0b204d2",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/shang-vikas/series1-coding-exercises/blob/main/exercises/blog-05/exercise-01.ipynb)\n",
    "\n",
    "# üß™ IMDB Sentiment Classification ‚Äî Vanilla RNN\n",
    "\n",
    "## 1Ô∏è‚É£ Install + Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f87e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install datasets -q\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import load_dataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from collections import Counter\n",
    "import time\n",
    "import re\n",
    "\n",
    "def basic_english_tokenizer(text):\n",
    "    \"\"\"Simple tokenizer that splits on whitespace and converts to lowercase.\"\"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z0-9\\s]', ' ', text)\n",
    "    return text.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f97043",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Load IMDB Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ba88ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load IMDB dataset from Hugging Face datasets\n",
    "dataset = load_dataset(\"imdb\")\n",
    "\n",
    "train_data = dataset['train']\n",
    "test_data = dataset['test']\n",
    "\n",
    "print(\"Train samples:\", len(train_data))\n",
    "print(\"Test samples:\", len(test_data))\n",
    "print(\"\\nSample review:\")\n",
    "print(\"Text:\", train_data[0]['text'][:100] + \"...\")\n",
    "print(\"Label:\", train_data[0]['label'], \"(0=neg, 1=pos)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa11309",
   "metadata": {},
   "source": [
    "IMDB contains:\n",
    "\n",
    "- 25,000 training reviews\n",
    "- 25,000 test reviews\n",
    "- Binary sentiment: pos / neg\n",
    "\n",
    "## 3Ô∏è‚É£ Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86863e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizer is defined above in imports\n",
    "tokenizer = basic_english_tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dbe5e3d",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Build Vocabulary\n",
    "\n",
    "We restrict vocab size to keep training manageable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb903078",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = Counter()\n",
    "\n",
    "for example in train_data:\n",
    "    text = example['text']\n",
    "    tokens = tokenizer(text)\n",
    "    counter.update(tokens)\n",
    "\n",
    "vocab_size = 20000\n",
    "most_common = counter.most_common(vocab_size - 2)\n",
    "\n",
    "vocab = {word: idx+2 for idx, (word, _) in enumerate(most_common)}\n",
    "vocab[\"<pad>\"] = 0\n",
    "vocab[\"<unk>\"] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42c2b26",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Numericalize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c07cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(text):\n",
    "    tokens = tokenizer(text)\n",
    "    return [vocab.get(token, vocab[\"<unk>\"]) for token in tokens]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51539856",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ Collate Function (Padding)\n",
    "\n",
    "RNNs need fixed batch lengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf27e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_batch(batch):\n",
    "    texts, labels = [], []\n",
    "    \n",
    "    for example in batch:\n",
    "        text = example['text']\n",
    "        label = example['label']  # Already 0 or 1\n",
    "        encoded = torch.tensor(encode(text))\n",
    "        texts.append(encoded)\n",
    "        labels.append(label)\n",
    "    \n",
    "    texts = pad_sequence(texts, batch_first=True)\n",
    "    labels = torch.tensor(labels)\n",
    "    \n",
    "    return texts, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8563b888",
   "metadata": {},
   "source": [
    "## 7Ô∏è‚É£ DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebeca39",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True, collate_fn=collate_batch)\n",
    "test_loader = DataLoader(test_data, batch_size=64, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a734ce0",
   "metadata": {},
   "source": [
    "## 8Ô∏è‚É£ Define Vanilla RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac4a0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VanillaRNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
    "        self.rnn = nn.RNN(embed_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        out, hidden = self.rnn(x)\n",
    "        \n",
    "        # Use last hidden state\n",
    "        final_hidden = hidden.squeeze(0)\n",
    "        return self.fc(final_hidden)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba99bb1",
   "metadata": {},
   "source": [
    "## 9Ô∏è‚É£ Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2008b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = VanillaRNN(vocab_size, embed_dim=100, hidden_dim=128).to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b538ca1d",
   "metadata": {},
   "source": [
    "## üîü Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f697b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for texts, labels in train_loader:\n",
    "        texts, labels = texts.to(device), labels.to(device).float()\n",
    "        \n",
    "        outputs = model(texts).squeeze()\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    return total_loss / len(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d87fae",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£1Ô∏è‚É£ Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9640b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate():\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for texts, labels in test_loader:\n",
    "            texts, labels = texts.to(device), labels.to(device)\n",
    "            outputs = torch.sigmoid(model(texts).squeeze())\n",
    "            preds = (outputs > 0.5).long()\n",
    "            \n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    \n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbad5c0",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£2Ô∏è‚É£ Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7581b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(5):\n",
    "    start = time.time()\n",
    "    \n",
    "    loss = train_epoch()\n",
    "    acc = evaluate()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1} | Loss: {loss:.4f} | Test Acc: {acc:.4f} | Time: {time.time()-start:.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c86bb3",
   "metadata": {},
   "source": [
    "You should see:\n",
    "\n",
    "- Accuracy around 80‚Äì85%.\n",
    "- Good.\n",
    "- But not state-of-the-art.\n",
    "\n",
    "And that's intentional.\n",
    "\n",
    "## ‚úÖ What This Exercise Teaches\n",
    "\n",
    "1Ô∏è‚É£ **Order matters**\n",
    "\n",
    "Unlike bag-of-words, performance is significantly higher.\n",
    "\n",
    "2Ô∏è‚É£ **Hidden state compresses entire review**\n",
    "\n",
    "Final decision comes from a single vector.\n",
    "\n",
    "3Ô∏è‚É£ **Same weights reused per timestep**\n",
    "\n",
    "True recurrence.\n",
    "\n",
    "## ‚ö†Ô∏è Shortfalls (Make These Visible)\n",
    "\n",
    "### ‚ùå 1. Long Reviews Hurt\n",
    "\n",
    "Increase max review length.\n",
    "\n",
    "You'll see:\n",
    "\n",
    "- Training slows\n",
    "- Accuracy plateaus\n",
    "\n",
    "Because:\n",
    "\n",
    "Information must travel through every timestep.\n",
    "\n",
    "### ‚ùå 2. Vanishing Gradients\n",
    "\n",
    "Check gradient norm of embedding layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8c5870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run one training step to get gradients\n",
    "texts, labels = next(iter(train_loader))\n",
    "texts, labels = texts.to(device), labels.to(device).float()\n",
    "\n",
    "outputs = model(texts).squeeze()\n",
    "loss = criterion(outputs, labels)\n",
    "\n",
    "optimizer.zero_grad()\n",
    "loss.backward()\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    if \"embedding\" in name and param.grad is not None:\n",
    "        print(\"Embedding grad norm:\", param.grad.norm().item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1674dca9",
   "metadata": {},
   "source": [
    "Increase sequence length ‚Üí gradient shrinks.\n",
    "\n",
    "### ‚ùå 3. Serial Computation\n",
    "\n",
    "Time per epoch scales roughly linearly with sequence length.\n",
    "\n",
    "You cannot parallelize across time.\n",
    "\n",
    "GPU underutilized.\n",
    "\n",
    "### ‚ùå 4. Fixed Memory Bottleneck\n",
    "\n",
    "All review meaning compressed into:\n",
    "\n",
    "```python\n",
    "hidden_dim = 128\n",
    "```\n",
    "\n",
    "Long review.\n",
    "Single 128-dim vector.\n",
    "\n",
    "Compression pressure.\n",
    "\n",
    "## üß† Why This Is Perfect Before LSTM\n",
    "\n",
    "Students now feel:\n",
    "\n",
    "- Memory compression\n",
    "- Gradient fragility\n",
    "- Sequential bottleneck\n",
    "\n",
    "So when you introduce LSTM gates later, it solves a problem they already experienced.\n",
    "\n",
    "Not abstractly.\n",
    "\n",
    "Mechanically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2f10e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b64c4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b3358c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9a8a0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c78ca8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d86562",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8f49b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1171d26e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
