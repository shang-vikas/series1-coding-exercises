{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07c1cebb",
   "metadata": {},
   "source": [
    "# Exercise 02: Neural Network from Scratch\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/shang-vikas/series1-coding-exercises/blob/main/exercises/blog-01/exercise-02.ipynb)\n",
    "\n",
    "This notebook demonstrates building a simple neural network from scratch using only NumPy.\n",
    "\n",
    "## Learning Objectives\n",
    "- Understand the basic structure of a neural network\n",
    "- Implement forward propagation manually\n",
    "- See how matrix multiplication drives neural networks\n",
    "- Apply activation functions (ReLU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c4aad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ numpy is already installed\n",
      "✓ scikit-learn is already installed\n",
      "✓ pandas is already installed\n"
     ]
    }
   ],
   "source": [
    "## 1. Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b01dea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ numpy is already installed\n",
      "✓ scikit-learn is already installed\n",
      "✓ pandas is already installed\n"
     ]
    }
   ],
   "source": [
    "# Install required packages using the kernel's Python interpreter\n",
    "import sys\n",
    "import subprocess\n",
    "import importlib\n",
    "\n",
    "\n",
    "def install_if_missing(package, import_name=None):\n",
    "    \"\"\"Install package if it's not already installed.\"\"\"\n",
    "    if import_name is None:\n",
    "        import_name = package\n",
    "    try:\n",
    "        importlib.import_module(import_name)\n",
    "        print(f\"✓ {package} is already installed\")\n",
    "    except ImportError:\n",
    "        print(f\"Installing {package}...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "        print(f\"✓ {package} installed successfully\")\n",
    "\n",
    "\n",
    "# Install required packages\n",
    "install_if_missing(\"numpy\")\n",
    "install_if_missing(\"scikit-learn\", \"sklearn\")\n",
    "install_if_missing(\"pandas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59d006bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df19459f",
   "metadata": {},
   "source": [
    "## 3. Define Input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7bf1464f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (2,)\n",
      "Input: [2. 3.]\n"
     ]
    }
   ],
   "source": [
    "# Example input (2 features)\n",
    "x = np.array([2.0, 3.0])\n",
    "print(f\"Input shape: {x.shape}\")\n",
    "print(f\"Input: {x}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48426b0f",
   "metadata": {},
   "source": [
    "## 4. Define Layer 1 (Hidden Layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87b4df3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1 shape: (2, 3)\n",
      "b1 shape: (3,)\n"
     ]
    }
   ],
   "source": [
    "# Layer 1 weights: shape (2, 3) - 2 inputs, 3 neurons\n",
    "W1 = np.array([\n",
    "    [0.5, -0.2, 0.1],\n",
    "    [0.3, 0.8, -0.5]\n",
    "])\n",
    "\n",
    "# Layer 1 bias: shape (3,)\n",
    "b1 = np.array([0.1, -0.1, 0.05])\n",
    "\n",
    "print(f\"W1 shape: {W1.shape}\")\n",
    "print(f\"b1 shape: {b1.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e1bf30",
   "metadata": {},
   "source": [
    "## 5. Forward Propagation Through Layer 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05c3eb3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1 pre-activation (z1): [ 2.    1.9  -1.25]\n",
      "Layer 1 output (a1): [2.  1.9 0. ]\n"
     ]
    }
   ],
   "source": [
    "# Linear transformation: z1 = x @ W1 + b1\n",
    "z1 = x @ W1 + b1\n",
    "\n",
    "# Apply ReLU activation function\n",
    "a1 = np.maximum(0, z1)  # ReLU: max(0, z)\n",
    "\n",
    "print(f\"Layer 1 pre-activation (z1): {z1}\")\n",
    "print(f\"Layer 1 output (a1): {a1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c313dd1",
   "metadata": {},
   "source": [
    "## 6. Define Output Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42ea7777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W2 shape: (3, 1)\n",
      "b2 shape: (1,)\n"
     ]
    }
   ],
   "source": [
    "# Output layer weights: shape (3, 1) - 3 inputs from layer 1, 1 output\n",
    "W2 = np.array([\n",
    "    [0.7],\n",
    "    [-0.3],\n",
    "    [0.2]\n",
    "])\n",
    "\n",
    "# Output layer bias: shape (1,)\n",
    "b2 = np.array([0.05])\n",
    "\n",
    "print(f\"W2 shape: {W2.shape}\")\n",
    "print(f\"b2 shape: {b2.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef6df7c",
   "metadata": {},
   "source": [
    "## 7. Forward Propagation Through Output Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7166562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final output: [0.88]\n",
      "Output shape: (1,)\n"
     ]
    }
   ],
   "source": [
    "# Linear transformation: z2 = a1 @ W2 + b2\n",
    "z2 = a1 @ W2 + b2\n",
    "output = z2\n",
    "\n",
    "print(f\"Final output: {output}\")\n",
    "print(f\"Output shape: {output.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a0f045",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### What Just Happened?\n",
    "\n",
    "You performed a complete forward pass through a neural network:\n",
    "\n",
    "**Input → Linear Transform → Non-linearity → Linear Transform → Output**\n",
    "\n",
    "That's a neural network in its essence:\n",
    "- **No brains**\n",
    "- **No magic**  \n",
    "- **Just matrix multiplications + simple functions**\n",
    "\n",
    "### Network Architecture\n",
    "\n",
    "```\n",
    "Input (2 features)\n",
    "    ↓\n",
    "Layer 1: 2 → 3 neurons (with ReLU activation)\n",
    "    ↓\n",
    "Output Layer: 3 → 1 neuron\n",
    "    ↓\n",
    "Final Output\n",
    "```\n",
    "\n",
    "### Key Concepts Demonstrated\n",
    "\n",
    "1. **Matrix Multiplication**: The core operation (`@` operator)\n",
    "2. **Bias Terms**: Added to shift the activation function\n",
    "3. **Activation Functions**: ReLU introduces non-linearity\n",
    "4. **Forward Propagation**: Data flows from input to output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
